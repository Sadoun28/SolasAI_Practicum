# SolasAI_Practicum

## Project Overview
## Basic Information

Person or organization developing model: 
*   Abdulrahman Alsadun (abdulrahman.alsadun@gwu.edu), Chao Zhang (chao.zhang@gwu.edu), Elena Huang (mengzhe_huang@gwu.edu), Jenny Yazlovsky (jyazlovsky@gwu.edu), Jinni Yang (jinni.yang@gwu.edu), Maximilian Smith-Uchida (msmithuchida814@gwu.edu)

## Problem Understanding

*   Central Issue: Increase the number of benchmark models SolasAI has access to.

*   Desired Business Outcomes: Build multiple different algorithm types that act as a baseline which can measure disparity: XGBoost, logistic regression, explainable boosting machine, and neural networks models.

*   Client expectations: Different types of models that can be used repeatedly and function as an internal self-check when testing new bias mitigation techniques.

## Risks, Effect, and How to Mitigate Disparity

*   Disparity in a model refers to the systematic error of a model to consistently underestimate or overestimate the true values of a target variable. Some variables will affect the model fit with the model. 

*   Bias can results in unfair outcomes, which perpetuate inequities in our society. Models can become inflexible and cause it to miss essential data or patterns, which leads to inaccurate predictions. It can also cause the model to be incorrect, which can't indicate the relationship between the independent variables and dependent variables. 

*   We should be careful with each variable, regularly check the model's performance and consider the appropriate features or predictors, increase model complexity, or use different modeling techniques.

## Project Goal and Expectation

*   To have a series of models that SolasAI can use in the future as a benchmark for novel bias mitigation methods.

## Included in the notebooks:


*   XGBoost, logistic regression, explainable boosting machine, and neural network.
*   Performance metrics 




